{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "from anomaly_tools import HDBAnomalyDetector\n",
    "from database_tools import PandasDBReader\n",
    "from fh_config import regression_vars, response_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We need to create a PandasDBReader to interface with anomaly detectors.\n",
    "states = ['FL']\n",
    "specialty = ['Cardiology']\n",
    "pdb_reader = PandasDBReader(\"./config.yaml\", states, specialty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Next, we compute the outlier counts from HDBSCAN.\n",
    "hdb = HDBAnomalyDetector(regression_vars, response_var, pdb_reader.d_f, use_response_var=True)\n",
    "min_cluster_size = 10  # Going with 15 for now, it's not too hard to update this later.\n",
    "hdb.get_outlier_scores(min_size=min_cluster_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We need a DataFrame that contains the actual outlier counts.\n",
    "counted_df = hdb.get_most_frequent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['QAMAR' 'SEDILLO' 'PAL' 'LEW' 'REDDY' 'CHALASANI' 'LEE' 'KHATIB'\n",
      " 'LIEBERMAN' 'RUGGIERI' 'RANDALL' 'VANROY' 'ALI' 'VAN DEN BERG' 'MANUBENS'\n",
      " 'BREDLAU' 'STEIN' 'ATTANTI' 'FERNS' 'GUMMADI']\n"
     ]
    }
   ],
   "source": [
    "print(counted_df.head(20)['last_name'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{80: ['QAMAR', 'PAL', 'SEDILLO', 'GOEL', 'CHALASANI', 'LEW', 'REDDY', 'ATTANTI', 'MANUBENS', 'BAJAJ', 'GUMMADI', 'VAN DEN BERG', 'PRESSMAN', 'RANDALL', 'LIEBERMAN', 'UPADYA', 'STEIN', 'SESHADRI', 'KHATIB', 'GARCIA'], 20: ['QAMAR', 'SEDILLO', 'PAL', 'LEW', 'CHALASANI', 'ATTANTI', 'KHATIB', 'REDDY', 'GOEL', 'BREDLAU', 'GUALA', 'LEE', 'VAN DEN BERG', 'GARCIA', 'RANDALL', 'MANUBENS', 'BHATTA', 'RUGGIERI', 'ZACHARIAH', 'ROSENFIELD'], 150: ['QAMAR', 'SEDILLO', 'LEW', 'PAL', 'CHALASANI', 'KHATIB', 'ATTANTI', 'REDDY', 'UPADYA', 'GOEL', 'GUMMADI', 'LEE', 'TAUSSIG', 'WILLARD', 'GUALA', 'SINGH', 'ANDERSON', 'MANUBENS', 'DUBLIN', 'YELAMANCHI'], 40: ['QAMAR', 'PAL', 'SEDILLO', 'CHALASANI', 'ATTANTI', 'LEW', 'UPADYA', 'MANUBENS', 'REDDY', 'VAN DEN BERG', 'KHATIB', 'RUGGIERI', 'GOEL', 'ZACHARIAH', 'RANDALL', 'BHATTA', 'ALONSO', 'SECKLER', 'BREDLAU', 'LIEBERMAN'], 100: ['QAMAR', 'SEDILLO', 'LEW', 'CHALASANI', 'PAL', 'KHATIB', 'REDDY', 'ATTANTI', 'UPADYA', 'GOEL', 'GUMMADI', 'TAUSSIG', 'LEE', 'GUALA', 'WILLARD', 'RUGGIERI', 'SINGH', 'BASNIGHT', 'BAJAJ', 'ANDERSON'], 10: ['QAMAR', 'SEDILLO', 'PAL', 'LEW', 'REDDY', 'CHALASANI', 'LEE', 'KHATIB', 'LIEBERMAN', 'RUGGIERI', 'RANDALL', 'VANROY', 'ALI', 'VAN DEN BERG', 'MANUBENS', 'BREDLAU', 'STEIN', 'ATTANTI', 'FERNS', 'GUMMADI'], 15: ['QAMAR', 'SEDILLO', 'PAL', 'LEW', 'CHALASANI', 'VANROY', 'REDDY', 'LEE', 'BHATTA', 'KHATIB', 'LIEBERMAN', 'RANDALL', 'ATTANTI', 'PRESSMAN', 'RUGGIERI', 'BOSWELL', 'RUBENSTEIN', 'JAMIDAR', 'WILLARD', 'STEIN']}\n"
     ]
    }
   ],
   "source": [
    "top_20_dict = {}\n",
    "for size in [10, 15, 20, 40, 80, 100, 150]:\n",
    "    hdb.get_outlier_scores(min_size=size)\n",
    "    counted_df = hdb.get_most_frequent()\n",
    "    top_20_dict[size] = list(counted_df.head(20)['last_name'].values)\n",
    "print(top_20_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# From this DataFrame we create a sliced DataFrame containing the columns for the new table.\n",
    "npi_column = list(counted_df.index)\n",
    "state_column = [geo_info['state'] for geo_info in counted_df['address'].values]\n",
    "lastname_column = counted_df['last_name']\n",
    "outlier_count_column = counted_df['outlier_count']\n",
    "provider_column = [specialty[0] for i in range(len(npi_column))]\n",
    "for_new_table_data = {'state': state_column, 'lastname': lastname_column, 'provider_type': provider_column, 'outlier_count': outlier_count_column}\n",
    "for_new_table = pd.DataFrame(data=for_new_table_data, index=npi_column)\n",
    "for_new_table.to_csv(\"/home/dan/tx_im.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Next step: Testing that everything worked\n",
    "import psycopg2\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          npi state   lastname provider_type  outlier_count\n",
      "0  1033145487    FL      QAMAR    Cardiology             48\n",
      "1  1982680179    FL    SEDILLO    Cardiology             34\n",
      "2  1376588582    FL        PAL    Cardiology             29\n",
      "3  1861485757    FL        LEW    Cardiology             21\n",
      "4  1760477269    FL  CHALASANI    Cardiology             21\n"
     ]
    }
   ],
   "source": [
    "with open(\"./config.yaml\", 'r') as f:\n",
    "    db_config = yaml.load(f)\n",
    "con = psycopg2.connect(database=db_config['database_name'],\n",
    "                       user=db_config['user_name'],\n",
    "                       password=db_config['password'])\n",
    "new_query = \"SELECT * from provider_anomaly_counts_hdb\"\n",
    "test_df = pd.read_sql_query(new_query, con)\n",
    "print(test_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
